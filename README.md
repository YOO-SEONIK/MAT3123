# MAT3123
MAT3123-Final Project

###Final 프로젝트의 목표는 속이 빈 고무 패킹의 열–기계 거동을 물리식으로 라벨링해 합성 데이터셋을 만들고, 이를 학습한 MLP서로게이트로 온도 변동 시나리오에서 응력 기반 ε–N 피로수명을 빠르게 예측한다.
해당 파일은
1. Data Setting (1~5)
2. Machine Learning (6~9)
3. PyTorch Surrogate Training (10)
4. Sensitivity Analysis (11~12)
5. Thermal-stress Simulation and Fatigue Assessment (13~15)
6. Life Prediction (16~17)
로 17개의 코드셀로 이루어져 있다.

# 1.Data Setting (1~5)
## 1.1 노트북 환경 체크 + 그래프 기본 설정
Python, Numpy, Pandas의 버전을 확인하고 그래프를 설정값을 조절한다.

## 1.2 내부 대류 열전달 계수 h
본 단계에서는 관 내 유동의 내부 대류 열전달계수 h를 계산해 이후 온도장/응력 해석의 경계조건으로 사용한다. 먼저 20-80 C 범위에서 물의 평균 물성치(열전도도 k, 점도 mu, 밀도 rho, 비열 cp, Prandtl 수 Pr)를 정의한다. 유속 U와 관내경 D_i로 Reynolds 수를 Re = rhoUD_i/mu 로 계산하고, 유동 상태를 판별한다. 층류(Re < 2300)에서는 완전발달 내부유동 가정으로 Nu = 3.66 을 사용한다. 난류(Re >= 2300)에서는 Dittus-Boelter 상관식 Nu = 0.023Re^0.8Pr^n 을 쓰며, 가열은 n = 0.4, 냉각은 n = 0.3 으로 둔다. 마지막으로 h = Nu*k/D_i 로 환산하여 단위 W/m^2-K 의 값을 얻는다. 이 근사는 원형 관, 매끈한 벽, 충분히 긴 관, 상수 물성 등의 단순화를 포함하므로, 고온/점도 변화가 큰 경우나 비원형 덕트, 입구영향이 큰 짧은 관에서는 보정 또는 다른 상관식 검토가 필요하다.

## 1.3 고무 링의 온도 분포 T(r)
이 단계는 속 빈 원통(고무 링)의 반지름 방향 정상상태 온도분포 T(r)를 구한다. 축대칭, 축방향 열흐름 무시, 고체 내부 생성열 0, k_solid 일정 가정에서 지배식은 d/dr(r dT/dr)=0 이고 해는 T(r)=C1ln(r)+C2 이다. 내부/외부 표면에는 대류 경계가 적용된다: r=ri 에서 -k dT/dr = h_i(T - Ti_inf), r=ro 에서 -k dT/dr = h_o*(T - To_inf). 이를 C1, C2에 대한 선형 2x2 방정식으로 정리해 행렬 M * [C1 C2]^T = rhs 를 만들고, numpy 선형해법으로 C1, C2를 푼다. 그런 다음 ri~ro 사이를 균일 격자(Nr_grid)로 샘플링해 T(r)=C1*ln(r)+C2 값을 계산해 반환한다. 출력은 반지름 벡터 r[m]와 온도 벡터 T[degC]이며, 이 분포는 이후 열팽창 변형률 및 응력 근사 계산의 입력으로 사용된다. 가정상 k와 물성은 상수이고, 복사나 비선형 효과는 무시한다.

## 1.4 온도→물성/열팽창→응력(근사) 라벨러
이 단계는 주어진 운전/재료 조건에서 고무 링의 최대 등가응력과 합격/불합격 라벨을 자동 생성하는 핵심 라벨러다. 먼저 평균 온도 T_avg로 온도의존 등가 탄성계수 E(T)=E25exp(-beta(T-25))를 계산한다. 이어 고무의 선형 열팽창 계수 alpha와 기준온도 T_ref를 사용해 열팽창 변형률 분포 eps_th(r)=alpha*(T(r)-T_ref)을 얻는다. 구조 거동은 단순화하여 외벽 둘레변형이 거의 0이라고 가정하고, 열팽창에 역행하는 기계 변형을 eps_mech=-eps_th로 두어 원주방향 응력을 sigma_theta=(E/(1-nu))*eps_mech로 근사한다. 이 분포의 절댓값 최대치를 최대 등가응력(보수적 von Mises 근사)으로 사용한다. label_one_sample은 다음 순서로 동작한다: (1) 유속 U, 내경 D_i로 내부 대류계수 h_i 계산, (2) 내부/외부 대류 경계와 고무 열전도율 k로 속 빈 원통의 정상상태 온도장 T(r) 해석, (3) T_avg로 E 산출, (4) eps_th(r) 계산, (5) sigma_theta(r)와 그 최대치 max_vm 산출, (6) 허용응력 sigma_allow와 비교해 pass_flag를 1/0으로 부여. 반환에는 r, T(r), E, eps_th(r), sigma_theta(r), max_vm, pass_flag, h_i가 포함되어 이후 데이터셋 생성과 모델 학습에 바로 쓸 수 있다. 선형 탄성, 등방 열팽창, nu≈0.49, 정상상태 열전달, 접촉/구속 단순화 등을 가정한다.

## 1.5 랜덤 데이터셋 생성 + 빠른 확인용 플롯
이 단계는 학습에 사용할 표준화된 테이블 데이터를 자동 생성한다. 먼저 난수 시드로 재현성을 확보한 뒤, 운전/재료 변수(U, T_in, T_amb, E25, beta, alpha, h_o)를 현실 범위에서 균일 샘플링한다. 각 샘플마다 4번의 물리 라벨러를 호출해 최대 등가응력 max_vm(회귀 타깃)과 허용응력 기준 pass(분류 타깃)를 계산하고, 이를 하나의 표(df)에 쌓아 CSV로 저장한다. 생성된 df.head()와 describe()를 통해 분포와 스케일을 즉시 점검하며, 컬럼은 입력 7개(U, T_in, T_amb, E25, beta, alpha, h_o)와 출력 2개(max_vm, pass)로 명확히 분리된다. 이어 “개별 프로파일들의 평균”이 아니라 “평균 파라미터에서 단일 해석”을 수행해, 평균 조건에서의 반지름 방향 온도 T(r)와 근사 hoop 응력 분포를 플롯하여 물리적으로 가능한지 시각적으로 검증한다. 마지막으로 데이터셋 합격률(pass_rate)과 평균 조건의 내부 대류계수 h_i, max_vm을 함께 출력해 기준을 잡는다. 이 산출물은 이후 scikit-learn/PyTorch에 그대로 투입할 수 있는 깔끔한 입력-타깃 테이블이며, 학습/검증 분할, 스케일링, 라벨 균형 점검 등의 후속 단계와 바로 연결된다.

# 2.Machine Learning (6~9)

## 2.6 CSV 로드 → 피처/타깃 지정 → 라벨 불균형 점검(보조 라벨) → 학습/테스트 분할
이 단계는 학습 입력과 타깃을 확정하고, 분류 타깃의 불균형을 완화해 안정적인 평가가 가능하도록 데이터를 준비한다. 먼저 dataset.csv를 읽어 입력 피처 7개(U, T_in, T_amb, E25, beta, alpha, h_o)와 회귀 타깃(max_vm), 분류 타깃(pass)을 지정한다. 이어 분류 타깃의 클래스 분포를 점검해 한쪽 클래스만 존재하거나 소수 클래스가 20개 미만이면 실제 분류 실습이 불안정하므로, 보조 라벨(pass_median) 을 생성한다. 보조 라벨은 회귀 타깃 max_vm의 중앙값을 기준 임계치로 두어 max_vm <= median 이면 1, 그 외 0으로 정의해 양/음 비율을 균형에 가깝게 만든다(노트: 이상적인 구현은 훈련 세트에서 계산한 중앙값을 임계치로 사용해 데이터 누설을 더욱 줄이는 것). 마지막으로 입력 X, 회귀 y_r, 분류 y_c를 구성하고, train_test_split(stratify=y_c) 로 80/20 분할을 수행한다. stratify 옵션은 학습/테스트 양쪽에 동일한 클래스 비율을 보장해, 불균형에 따른 평가 편차를 줄인다. 결과적으로 이 단계는 회귀와 분류 모두에 대해 일관된 입력/타깃 정의, 불균형 방지 장치, 재현 가능한 분할(random_state=42)을 한 번에 수행하여 이후 모델 학습(7~8단계)과 교차검증이 신뢰성 있게 진행되도록 기반을 마련한다

## 2.7 회귀 베이스라인 학습/평가
이 단계는 max_vm(회귀 타깃)을 예측하기 위한 기본 회귀 모델들을 한 번에 학습하고 비교한다. 먼저 KFold(n_splits=5, shuffle=True, random_state=42)로 교차검증 분할자를 만들고, 모든 모델은 파이프라인을 통해 입력 표준화(StandardScaler)를 선행하여 데이터 누설을 방지한다(스케일러는 훈련 fold에서만 fit, 검증/테스트에는 transform만 적용). 비교 대상은 (1) LinearRegression 파이프라인, (2) Ridge 회귀의 하이퍼파라미터 alpha를 GridSearchCV로 탐색하는 파이프라인, (3) RandomForestRegressor의 n_estimators, max_depth, min_samples_leaf를 그리드로 탐색하는 구성이다. 각 모델은 훈련 세트로 학습 후 테스트 세트에서 예측을 수행하고, 평가 지표는 RMSE(작을수록 좋음)와 R2(클수록 좋음, 음수면 기준선보다 나쁨)를 사용한다. GridSearchCV 객체의 경우 .fit()이 끝나면 내부적으로 최적 하이퍼파라미터로 전체 훈련 세트를 재학습하므로, 이후 .predict()는 최적 모델을 사용한다. 또한 best_params_를 함께 기록해 어떤 설정이 선택되었는지 투명하게 남긴다. 최종적으로 모델명, RMSE, R2, best_params를 DataFrame(reg_results)에 모아 한눈에 비교할 수 있도록 정리하며, 이 표는 이후 단계에서 최고 성능 회귀 모델 선 및 정합(Parity) 플롯(9번) 생성의 근거 자료가 된다.

## 2.8 분류 베이스라인 학습/튜닝/평가
이 단계는 허용응력 기준의 합격/불합격 레이블을 예측하는 기본 분류기를 한 번에 학습하고 비교한다. 각 모델은 공정 비교와 누설 방지를 위해 동일한 분할(6단계)과 동일한 교차검증 설정(cv=KFold(5, shuffle=True, random_state=42))을 사용한다. 로지스틱 회귀(LogReg)는 StandardScaler를 포함한 파이프라인으로 감싸고 정규화 강도 C를 그리드로 탐색한다. 결정나무(DT)는 max_depth, min_samples_leaf를, 랜덤포레스트(RF)는 트리 수/깊이/리프 최소샘플을 그리드로 탐색한다. 모든 모델은 GridSearchCV로 최적 하이퍼파라미터를 찾은 뒤 그 설정으로 전체 학습 세트를 재학습해 테스트셋을 예측한다. 평가는 정확도(ACC), 불균형에 강한 F1, 확률 기반 판별력을 보는 ROC-AUC로 수행한다. ROC-AUC는 가능하면 predict_proba의 양성(1) 확률을, 없으면 decision_function 출력을 사용하며, 후자는 단조성만 유지되면 되므로 0-1 min-max로 스케일해도 AUC 해석에 문제가 없다. 결과를 표로 정리한 뒤 F1→AUC 우선 정렬로 최상 모델을 고르고, 혼동행렬과 classification_report로 오탐/미탐 구조를 구체적으로 해석한다(예: 실제 불합격 중 합격으로 본 개수 등). 운영 목적이 미검출 최소화라면, 선택한 모델의 확률 출력에 대해 임계값을 0.5에서 조정하여 프리시전-리콜 트레이드오프를 맞추는 것을 권장한다. 트리/포레스트는 feature_importances_로 입력 변수 영향도를 간단히 확인할 수 있고, 로지스틱은 계수 부호로 해석 가능해 원인 분석에 유용하다.

## 2.9 랜덤포레스트 중요도 시각화 및 회귀 정합 플롯
이 단계는 모델이 무엇을 보고 예측하는지, 그리고 예측이 실제 값과 얼마나 일치하는지를 빠르게 진단한다. 먼저 회귀/분류 각각의 RandomForest에서 feature_importances_를 꺼내 막대그래프로 표시해, 입력 변수(U, T_in, T_amb, E25, beta, alpha, h_o) 중 영향력이 큰 순서를 확인한다. 이는 설계 변수 조정의 우선순위를 정하거나, 데이터 수집/감지 센서의 중요도를 판단하는 근거가 된다. 다음으로 회귀 탑 성능 모델(예: RF-GS)을 선택해 테스트셋에서 예측값과 정답을 산점도(Parity plot)로 비교한다. 점들이 대각선(y=x) 부근에 모이면 정합이 좋고, 체계적인 곡률이나 꼬리 부분의 편차가 보이면 비선형성 미모델링, 데이터 범위 바깥 예측, 타깃 스케일 이슈 등을 의심할 수 있다. 이 플롯은 RMSE/R2 같은 단일 수치가 놓치기 쉬운 오류 패턴(언더/오버 예측 영역, 극값 왜곡)을 시각적으로 드러내며, 후속으로 모델 교체(예: 더 깊은 트리, 추가 특성), 입력 스케일 조정, 이상치 점검 등의 개선 방향을 결정하는 데 유용하다.

# 3. PyTorch Surrogate Training (10)

## 3.10 MLP 서로게이트(수동 SGD) 학습/평가
이 단계는 PyTorch로 간단한 MLP(2×128 ReLU)를 학습해 물리 라벨 max_vm을 빠르게 예측하는 서로게이트를 만든다. 먼저 입력을 StandardScaler로 표준화하고, 타깃은 log10 변환해 스케일을 안정화한다. torch.optim을 쓰지 않고 순수 SGD 스텝을 직접 구현해(grad 계산 → L2 weight decay 더하기 → 파라미터 갱신) 라이브러리 의존 이슈를 회피하면서도 동작을 투명하게 유지한다. 학습은 미니배치, MSE 손실(로그공간), 검증 MSE 모니터링, 조기 종료(patience)로 구성된다. 에폭마다 train/val 손실을 기록해 수렴과 과적합을 시각화하고, 최저 검증 손실 시점의 가중치를 best_state로 저장해 복원한다. 평가 시에는 예측(log10)을 원공간으로 되돌려 Pa 단위 RMSE를 보고하고, Parity plot(정답 vs 예측)을익
학습 입력과 타깃을 확정하고, 분류 타깃의 불균형을 완화해 안정적인 평가가 가능하도록 데이터를 준비한다. 먼저 dataset.csv를 읽어 입력 피처 7개(U, T_in, T_amb, E25, beta, alpha, h_o)와 회귀 타깃(max_vm), 분류 타깃(pass)을 지정한다. 이어 분류 타깃의 클래스 분포를 점검해 한쪽 클래스만 존재하거나 소수 클래스가 20개 미만이면 실제 분류 실습이 불안정하므로, 보조 라벨(pass_median) 을 생성한다. 보조 라벨은 회귀 타깃 max_vm의 중앙값을 기준 임계치로 두어 max_vm <= median 이면 1, 그 외 0으로 정의해 양/음 비율을 균형에 가깝게 만든다(노트: 이상적인 구현은 훈련 세트에서 계산한 중앙값을 임계치로 사용해 데이터 누설을 더욱 줄이는 것). 마지막으로 입력 X, 회귀 y_r, 분류 y_c를 구성하고, train_test_split(stratify=y_c) 로 80/20 분할을 수행한다. stratify 옵션은 학습/테스트 양쪽에 동일한 클래스 비율을 보장해, 불균형에 따른 평가 편차를 줄인다. 결과적으로 이 단계는 회귀와 분류 모두에 대해 일관된 입력/타깃 정의, 불균형 방지 장치, 재현 가능한 분할(random_state=42)을 한 번에 수행하여 이후 모델 학습(7~8단계)과 교차검증이 신뢰성 있게 진행되도록 기반을 마련한다

## 2.7 회귀 베이스라인 학습/평가
이 단계는 max_vm(회귀 타깃)을 예측하기 위한 기본 회귀 모델들을 한 번에 학습하고 비교한다. 먼저 KFold(n_splits=5, shuffle=True, random_state=42)로 교차검증 분할자를 만들고, 모든 모델은 파이프라인을 통해 입력 표준화(StandardScaler)를 선행하여 데이터 누설을 방지한다(스케일러는 훈련 fold에서만 fit, 검증/테스트에는 transform만 적용). 비교 대상은 (1) LinearRegression 파이프라인, (2) Ridge 회귀의 하이퍼파라미터 alpha를 GridSearchCV로 탐색하는 파이프라인, (3) RandomForestRegressor의 n_estimators, max_depth, min_samples_leaf를 그리드로 탐색하는 구성이다. 각 모델은 훈련 세트로 학습 후 테스트 세트에서 예측을 수행하고, 평가 지표는 RMSE(작을수록 좋음)와 R2(클수록 좋음, 음수면 기준선보다 나쁨)를 사용한다. GridSearchCV 객체의 경우 .fit()이 끝나면 내부적으로 최적 하이퍼파라미터로 전체 훈련 세트를 재학습하므로, 이후 .predict()는 최적 모델을 사용한다. 또한 best_params_를 함께 기록해 어떤 설정이 선택되었는지 투명하게 남긴다. 최종적으로 모델명, RMSE, R2, best_params를 DataFrame(reg_results)에 모아 한눈에 비교할 수 있도록 정리하며, 이 표는 이후 단계에서 최고 성능 회귀 모델 선 및 정합(Parity) 플롯(9번) 생성의 근거 자료가 된다.

## 2.8 분류 베이스라인 학습/튜닝/평가
이 단계는 허용응력 기준의 합격/불합격 레이블을 예측하는 기본 분류기를 한 번에 학습하고 비교한다. 각 모델은 공정 비교와 누설 방지를 위해 동일한 분할(6단계)과 동일한 교차검증 설정(cv=KFold(5, shuffle=True, random_state=42))을 사용한다. 로지스틱 회귀(LogReg)는 StandardScaler를 포함한 파이프라인으로 감싸고 정규화 강도 C를 그리드로 탐색한다. 결정나무(DT)는 max_depth, min_samples_leaf를, 랜덤포레스트(RF)는 트리 수/깊이/리프 최소샘플을 그리드로 탐색한다. 모든 모델은 GridSearchCV로 최적 하이퍼파라미터를 찾은 뒤 그 설정으로 전체 학습 세트를 재학습해 테스트셋을 예측한다. 평가는 정확도(ACC), 불균형에 강한 F1, 확률 기반 판별력을 보는 ROC-AUC로 수행한다. ROC-AUC는 가능하면 predict_proba의 양성(1) 확률을, 없으면 decision_function 출력을 사용하며, 후자는 단조성만 유지되면 되므로 0-1 min-max로 스케일해도 AUC 해석에 문제가 없다. 결과를 표로 정리한 뒤 F1→AUC 우선 정렬로 최상 모델을 고르고, 혼동행렬과 classification_report로 오탐/미탐 구조를 구체적으로 해석한다(예: 실제 불합격 중 합격으로 본 개수 등). 운영 목적이 미검출 최소화라면, 선택한 모델의 확률 출력에 대해 임계값을 0.5에서 조정하여 프리시전-리콜 트레이드오프를 맞추는 것을 권장한다. 트리/포레스트는 feature_importances_로 입력 변수 영향도를 간단히 확인할 수 있고, 로지스틱은 계수 부호로 해석 가능해 원인 분석에 유용하다.

## 2.9 랜덤포레스트 중요도 시각화 및 회귀 정합 플롯
이 단계는 모델이 무엇을 보고 예측하는지, 그리고 예측이 실제 값과 얼마나 일치하는지를 빠르게 진단한다. 먼저 회귀/분류 각각의 RandomForest에서 feature_importances_를 꺼내 막대그래프로 표시해, 입력 변수(U, T_in, T_amb, E25, beta, alpha, h_o) 중 영향력이 큰 순서를 확인한다. 이는 설계 변수 조정의 우선순위를 정하거나, 데이터 수집/감지 센서의 중요도를 판단하는 근거가 된다. 다음으로 회귀 탑 성능 모델(예: RF-GS)을 선택해 테스트셋에서 예측값과 정답을 산점도(Parity plot)로 비교한다. 점들이 대각선(y=x) 부근에 모이면 정합이 좋고, 체계적인 곡률이나 꼬리 부분의 편차가 보이면 비선형성 미모델링, 데이터 범위 바깥 예측, 타깃 스케일 이슈 등을 의심할 수 있다. 이 플롯은 RMSE/R2 같은 단일 수치가 놓치기 쉬운 오류 패턴(언더/오버 예측 영역, 극값 왜곡)을 시각적으로 드러내며, 후속으로 모델 교체(예: 더 깊은 트리, 추가 특성), 입력 스케일 조정, 이상치 점검 등의 개선 방향을 결정하는 데 유용하다.

# 3. PyTorch Surrogate Training (10)

## 3.10 MLP 서로게이트(수동 SGD) 학습/평가
이 단계는 PyTorch로 간단한 MLP(2×128 ReLU)를 학습해 물리 라벨 max_vm을 빠르게 예측하는 서로게이트를 만든다. 먼저 입력을 StandardScaler로 표준화하고, 타깃은 log10 변환해 스케일을 안정화한다. torch.optim을 쓰지 않고 순수 SGD 스텝을 직접 구현해(grad 계산 → L2 weight decay 더하기 → 파라미터 갱신) 라이브러리 의존 이슈를 회피하면서도 동작을 투명하게 유지한다. 학습은 미니배치, MSE 손실(로그공간), 검증 MSE 모니터링, 조기 종료(patience)로 구성된다. 에폭마다 train/val 손실을 기록해 수렴과 과적합을 시각화하고, 최저 검증 손실 시점의 가중치를 best_state로 저장해 복원한다. 평가 시에는 예측(log10)을 원공간으로 되돌려 Pa 단위 RMSE를 보고하고, Parity plot(정답 vs 예측)을익











학습 입력과 타깃을 확정하고, 분류 타깃의 불균형을 완화해 안정적인 평가가 가능하도록 데이터를 준비한다. 먼저 dataset.csv를 읽어 입력 피처 7개(U, T_in, T_amb, E25, beta, alpha, h_o)와 회귀 타깃(max_vm), 분류 타깃(pass)을 지정한다. 이어 분류 타깃의 클래스 분포를 점검해 한쪽 클래스만 존재하거나 소수 클래스가 20개 미만이면 실제 분류 실습이 불안정하므로, 보조 라벨(pass_median) 을 생성한다. 보조 라벨은 회귀 타깃 max_vm의 중앙값을 기준 임계치로 두어 max_vm <= median 이면 1, 그 외 0으로 정의해 양/음 비율을 균형에 가깝게 만든다(노트: 이상적인 구현은 훈련 세트에서 계산한 중앙값을 임계치로 사용해 데이터 누설을 더욱 줄이는 것). 마지막으로 입력 X, 회귀 y_r, 분류 y_c를 구성하고, train_test_split(stratify=y_c) 로 80/20 분할을 수행한다. stratify 옵션은 학습/테스트 양쪽에 동일한 클래스 비율을 보장해, 불균형에 따른 평가 편차를 줄인다. 결과적으로 이 단계는 회귀와 분류 모두에 대해 일관된 입력/타깃 정의, 불균형 방지 장치, 재현 가능한 분할(random_state=42)을 한 번에 수행하여 이후 모델 학습(7~8단계)과 교차검증이 신뢰성 있게 진행되도록 기반을 마련한다

## 2.7 회귀 베이스라인 학습/평가
이 단계는 max_vm(회귀 타깃)을 예측하기 위한 기본 회귀 모델들을 한 번에 학습하고 비교한다. 먼저 KFold(n_splits=5, shuffle=True, random_state=42)로 교차검증 분할자를 만들고, 모든 모델은 파이프라인을 통해 입력 표준화(StandardScaler)를 선행하여 데이터 누설을 방지한다(스케일러는 훈련 fold에서만 fit, 검증/테스트에는 transform만 적용). 비교 대상은 (1) LinearRegression 파이프라인, (2) Ridge 회귀의 하이퍼파라미터 alpha를 GridSearchCV로 탐색하는 파이프라인, (3) RandomForestRegressor의 n_estimators, max_depth, min_samples_leaf를 그리드로 탐색하는 구성이다. 각 모델은 훈련 세트로 학습 후 테스트 세트에서 예측을 수행하고, 평가 지표는 RMSE(작을수록 좋음)와 R2(클수록 좋음, 음수면 기준선보다 나쁨)를 사용한다. GridSearchCV 객체의 경우 .fit()이 끝나면 내부적으로 최적 하이퍼파라미터로 전체 훈련 세트를 재학습하므로, 이후 .predict()는 최적 모델을 사용한다. 또한 best_params_를 함께 기록해 어떤 설정이 선택되었는지 투명하게 남긴다. 최종적으로 모델명, RMSE, R2, best_params를 DataFrame(reg_results)에 모아 한눈에 비교할 수 있도록 정리하며, 이 표는 이후 단계에서 최고 성능 회귀 모델 선 및 정합(Parity) 플롯(9번) 생성의 근거 자료가 된다.

## 2.8 분류 베이스라인 학습/튜닝/평가
이 단계는 허용응력 기준의 합격/불합격 레이블을 예측하는 기본 분류기를 한 번에 학습하고 비교한다. 각 모델은 공정 비교와 누설 방지를 위해 동일한 분할(6단계)과 동일한 교차검증 설정(cv=KFold(5, shuffle=True, random_state=42))을 사용한다. 로지스틱 회귀(LogReg)는 StandardScaler를 포함한 파이프라인으로 감싸고 정규화 강도 C를 그리드로 탐색한다. 결정나무(DT)는 max_depth, min_samples_leaf를, 랜덤포레스트(RF)는 트리 수/깊이/리프 최소샘플을 그리드로 탐색한다. 모든 모델은 GridSearchCV로 최적 하이퍼파라미터를 찾은 뒤 그 설정으로 전체 학습 세트를 재학습해 테스트셋을 예측한다. 평가는 정확도(ACC), 불균형에 강한 F1, 확률 기반 판별력을 보는 ROC-AUC로 수행한다. ROC-AUC는 가능하면 predict_proba의 양성(1) 확률을, 없으면 decision_function 출력을 사용하며, 후자는 단조성만 유지되면 되므로 0-1 min-max로 스케일해도 AUC 해석에 문제가 없다. 결과를 표로 정리한 뒤 F1→AUC 우선 정렬로 최상 모델을 고르고, 혼동행렬과 classification_report로 오탐/미탐 구조를 구체적으로 해석한다(예: 실제 불합격 중 합격으로 본 개수 등). 운영 목적이 미검출 최소화라면, 선택한 모델의 확률 출력에 대해 임계값을 0.5에서 조정하여 프리시전-리콜 트레이드오프를 맞추는 것을 권장한다. 트리/포레스트는 feature_importances_로 입력 변수 영향도를 간단히 확인할 수 있고, 로지스틱은 계수 부호로 해석 가능해 원인 분석에 유용하다.

## 2.9 랜덤포레스트 중요도 시각화 및 회귀 정합 플롯
이 단계는 모델이 무엇을 보고 예측하는지, 그리고 예측이 실제 값과 얼마나 일치하는지를 빠르게 진단한다. 먼저 회귀/분류 각각의 RandomForest에서 feature_importances_를 꺼내 막대그래프로 표시해, 입력 변수(U, T_in, T_amb, E25, beta, alpha, h_o) 중 영향력이 큰 순서를 확인한다. 이는 설계 변수 조정의 우선순위를 정하거나, 데이터 수집/감지 센서의 중요도를 판단하는 근거가 된다. 다음으로 회귀 탑 성능 모델(예: RF-GS)을 선택해 테스트셋에서 예측값과 정답을 산점도(Parity plot)로 비교한다. 점들이 대각선(y=x) 부근에 모이면 정합이 좋고, 체계적인 곡률이나 꼬리 부분의 편차가 보이면 비선형성 미모델링, 데이터 범위 바깥 예측, 타깃 스케일 이슈 등을 의심할 수 있다. 이 플롯은 RMSE/R2 같은 단일 수치가 놓치기 쉬운 오류 패턴(언더/오버 예측 영역, 극값 왜곡)을 시각적으로 드러내며, 후속으로 모델 교체(예: 더 깊은 트리, 추가 특성), 입력 스케일 조정, 이상치 점검 등의 개선 방향을 결정하는 데 유용하다.

# 3. PyTorch Surrogate Training (10)

## 3.10 MLP 서로게이트(수동 SGD) 학습/평가
이 단계는 PyTorch로 간단한 MLP(2×128 ReLU)를 학습해 물리 라벨 max_vm을 빠르게 예측하는 서로게이트를 만든다. 먼저 입력을 StandardScaler로 표준화하고, 타깃은 log10 변환해 스케일을 안정화한다. torch.optim을 쓰지 않고 순수 SGD 스텝을 직접 구현해(grad 계산 → L2 weight decay 더하기 → 파라미터 갱신) 라이브러리 의존 이슈를 회피하면서도 동작을 투명하게 유지한다. 학습은 미니배치, MSE 손실(로그공간), 검증 MSE 모니터링, 조기 종료(patience)로 구성된다. 에폭마다 train/val 손실을 기록해 수렴과 과적합을 시각화하고, 최저 검증 손실 시점의 가중치를 best_state로 저장해 복원한다. 평가 시에는 예측(log10)을 원공간으로 되돌려 Pa 단위 RMSE를 보고하고, Parity plot(정답 vs 예측)을익








학습 입력과 타깃을 확정하고, 분류 타깃의 불균형을 완화해 안정적인 평가가 가능하도록 데이터를 준비한다. 먼저 dataset.csv를 읽어 입력 피처 7개(U, T_in, T_amb, E25, beta, alpha, h_o)와 회귀 타깃(max_vm), 분류 타깃(pass)을 지정한다. 이어 분류 타깃의 클래스 분포를 점검해 한쪽 클래스만 존재하거나 소수 클래스가 20개 미만이면 실제 분류 실습이 불안정하므로, 보조 라벨(pass_median) 을 생성한다. 보조 라벨은 회귀 타깃 max_vm의 중앙값을 기준 임계치로 두어 max_vm <= median 이면 1, 그 외 0으로 정의해 양/음 비율을 균형에 가깝게 만든다(노트: 이상적인 구현은 훈련 세트에서 계산한 중앙값을 임계치로 사용해 데이터 누설을 더욱 줄이는 것). 마지막으로 입력 X, 회귀 y_r, 분류 y_c를 구성하고, train_test_split(stratify=y_c) 로 80/20 분할을 수행한다. stratify 옵션은 학습/테스트 양쪽에 동일한 클래스 비율을 보장해, 불균형에 따른 평가 편차를 줄인다. 결과적으로 이 단계는 회귀와 분류 모두에 대해 일관된 입력/타깃 정의, 불균형 방지 장치, 재현 가능한 분할(random_state=42)을 한 번에 수행하여 이후 모델 학습(7~8단계)과 교차검증이 신뢰성 있게 진행되도록 기반을 마련한다

## 2.7 회귀 베이스라인 학습/평가
이 단계는 max_vm(회귀 타깃)을 예측하기 위한 기본 회귀 모델들을 한 번에 학습하고 비교한다. 먼저 KFold(n_splits=5, shuffle=True, random_state=42)로 교차검증 분할자를 만들고, 모든 모델은 파이프라인을 통해 입력 표준화(StandardScaler)를 선행하여 데이터 누설을 방지한다(스케일러는 훈련 fold에서만 fit, 검증/테스트에는 transform만 적용). 비교 대상은 (1) LinearRegression 파이프라인, (2) Ridge 회귀의 하이퍼파라미터 alpha를 GridSearchCV로 탐색하는 파이프라인, (3) RandomForestRegressor의 n_estimators, max_depth, min_samples_leaf를 그리드로 탐색하는 구성이다. 각 모델은 훈련 세트로 학습 후 테스트 세트에서 예측을 수행하고, 평가 지표는 RMSE(작을수록 좋음)와 R2(클수록 좋음, 음수면 기준선보다 나쁨)를 사용한다. GridSearchCV 객체의 경우 .fit()이 끝나면 내부적으로 최적 하이퍼파라미터로 전체 훈련 세트를 재학습하므로, 이후 .predict()는 최적 모델을 사용한다. 또한 best_params_를 함께 기록해 어떤 설정이 선택되었는지 투명하게 남긴다. 최종적으로 모델명, RMSE, R2, best_params를 DataFrame(reg_results)에 모아 한눈에 비교할 수 있도록 정리하며, 이 표는 이후 단계에서 최고 성능 회귀 모델 선 및 정합(Parity) 플롯(9번) 생성의 근거 자료가 된다.

## 2.8 분류 베이스라인 학습/튜닝/평가
이 단계는 허용응력 기준의 합격/불합격 레이블을 예측하는 기본 분류기를 한 번에 학습하고 비교한다. 각 모델은 공정 비교와 누설 방지를 위해 동일한 분할(6단계)과 동일한 교차검증 설정(cv=KFold(5, shuffle=True, random_state=42))을 사용한다. 로지스틱 회귀(LogReg)는 StandardScaler를 포함한 파이프라인으로 감싸고 정규화 강도 C를 그리드로 탐색한다. 결정나무(DT)는 max_depth, min_samples_leaf를, 랜덤포레스트(RF)는 트리 수/깊이/리프 최소샘플을 그리드로 탐색한다. 모든 모델은 GridSearchCV로 최적 하이퍼파라미터를 찾은 뒤 그 설정으로 전체 학습 세트를 재학습해 테스트셋을 예측한다. 평가는 정확도(ACC), 불균형에 강한 F1, 확률 기반 판별력을 보는 ROC-AUC로 수행한다. ROC-AUC는 가능하면 predict_proba의 양성(1) 확률을, 없으면 decision_function 출력을 사용하며, 후자는 단조성만 유지되면 되므로 0-1 min-max로 스케일해도 AUC 해석에 문제가 없다. 결과를 표로 정리한 뒤 F1→AUC 우선 정렬로 최상 모델을 고르고, 혼동행렬과 classification_report로 오탐/미탐 구조를 구체적으로 해석한다(예: 실제 불합격 중 합격으로 본 개수 등). 운영 목적이 미검출 최소화라면, 선택한 모델의 확률 출력에 대해 임계값을 0.5에서 조정하여 프리시전-리콜 트레이드오프를 맞추는 것을 권장한다. 트리/포레스트는 feature_importances_로 입력 변수 영향도를 간단히 확인할 수 있고, 로지스틱은 계수 부호로 해석 가능해 원인 분석에 유용하다.

## 2.9 랜덤포레스트 중요도 시각화 및 회귀 정합 플롯
이 단계는 모델이 무엇을 보고 예측하는지, 그리고 예측이 실제 값과 얼마나 일치하는지를 빠르게 진단한다. 먼저 회귀/분류 각각의 RandomForest에서 feature_importances_를 꺼내 막대그래프로 표시해, 입력 변수(U, T_in, T_amb, E25, beta, alpha, h_o) 중 영향력이 큰 순서를 확인한다. 이는 설계 변수 조정의 우선순위를 정하거나, 데이터 수집/감지 센서의 중요도를 판단하는 근거가 된다. 다음으로 회귀 탑 성능 모델(예: RF-GS)을 선택해 테스트셋에서 예측값과 정답을 산점도(Parity plot)로 비교한다. 점들이 대각선(y=x) 부근에 모이면 정합이 좋고, 체계적인 곡률이나 꼬리 부분의 편차가 보이면 비선형성 미모델링, 데이터 범위 바깥 예측, 타깃 스케일 이슈 등을 의심할 수 있다. 이 플롯은 RMSE/R2 같은 단일 수치가 놓치기 쉬운 오류 패턴(언더/오버 예측 영역, 극값 왜곡)을 시각적으로 드러내며, 후속으로 모델 교체(예: 더 깊은 트리, 추가 특성), 입력 스케일 조정, 이상치 점검 등의 개선 방향을 결정하는 데 유용하다.

# 3. PyTorch Surrogate Training (10)

## 3.10 MLP 서로게이트(수동 SGD) 학습/평가
이 단계는 PyTorch로 간단한 MLP(2×128 ReLU)를 학습해 물리 라벨 max_vm을 빠르게 예측하는 서로게이트를 만든다. 먼저 입력을 StandardScaler로 표준화하고, 타깃은 log10 변환해 스케일을 안정화한다. torch.optim을 쓰지 않고 순수 SGD 스텝을 직접 구현해(grad 계산 → L2 weight decay 더하기 → 파라미터 갱신) 라이브러리 의존 이슈를 회피하면서도 동작을 투명하게 유지한다. 학습은 미니배치, MSE 손실(로그공간), 검증 MSE 모니터링, 조기 종료(patience)로 구성된다. 에폭마다 train/val 손실을 기록해 수렴과 과적합을 시각화하고, 최저 검증 손실 시점의 가중치를 best_state로 저장해 복원한다. 평가 시에는 예측(log10)을 원공간으로 되돌려 Pa 단위 RMSE를 보고하고, Parity plot(정답 vs 예측)을익

